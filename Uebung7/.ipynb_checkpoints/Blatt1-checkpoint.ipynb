{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11054460569030580481\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1743585280\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7829212675196043361\n",
      "physical_device_desc: \"device: 0, name: Quadro K620, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "#!pip install --upgrade keras==2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/informatik2/students/home/6krekele/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() #CIFAR-10 Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES=10\n",
    "X_train = X_train.astype('float32') / 225.0\n",
    "X_test = X_test.astype('float32') / 225.0\n",
    "y_train = keras.utils.to_categorical(y_train,NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "dataset_size = X_train.shape[0]\n",
    "\n",
    "idx = random.randint(0, dataset_size)\n",
    "\n",
    "sample_img = X_train[idx]\n",
    "sample_label= np.argmax(y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beispiel Bild anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "labeldict = {}\n",
    "for i,x in enumerate(labels):\n",
    "    labeldict[i]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_Label : automobile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbc225be860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(u\"Sample_Label : %s\" % labeldict[sample_label])\n",
    "plt.imshow(sample_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erzeugung des CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D, Dense\n",
    "from keras.layers import Dropout, Activation , Flatten\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(5,5),padding ='same',input_shape=input_shape)) # 5x5x32' Conv \n",
    "model.add(Activation('relu')) # relu\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))# 3x3x32 Conv\n",
    "model.add(MaxPool2D(pool_size=(2,2))) # 2x2 max pool \n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.25)) #\n",
    "\n",
    "model.add(Conv2D(64,(3,3),padding='same')) # 3x3x64\n",
    "model.add(Activation('relu')) # relu\n",
    "\n",
    "model.add(Conv2D(64,(3,3))) # 3x3x64'\n",
    "model.add(MaxPool2D(pool_size=(2,2)))# 2x2  maxpool\n",
    "#model.add(Dropout(0.5)) # Dropout \n",
    "\n",
    "model.add(Flatten()) # \n",
    "model.add(Dense(1024,activation='relu')) # Hidden Layer\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(NUM_CLASSES,activation='softmax'))  # Softmax\n",
    "\n",
    "LEARNING_RATE = 0\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 138s 3ms/step - loss: 2.1838 - acc: 0.2053 - val_loss: 3.1303 - val_acc: 0.1927\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 1.7673 - acc: 0.3763 - val_loss: 1.4865 - val_acc: 0.4697\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 1.4771 - acc: 0.4791 - val_loss: 1.4333 - val_acc: 0.4760\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 34s 672us/step - loss: 1.3349 - acc: 0.5308 - val_loss: 1.2817 - val_acc: 0.5529\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 1.1738 - acc: 0.5892 - val_loss: 1.1951 - val_acc: 0.5743\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 1.0683 - acc: 0.6290 - val_loss: 1.1587 - val_acc: 0.5941\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 0.9666 - acc: 0.6662 - val_loss: 1.0373 - val_acc: 0.6352\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 0.8483 - acc: 0.7057 - val_loss: 0.9722 - val_acc: 0.6667\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 0.7219 - acc: 0.7519 - val_loss: 1.0932 - val_acc: 0.6369\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 34s 673us/step - loss: 0.6444 - acc: 0.7804 - val_loss: 1.0028 - val_acc: 0.6617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc22596080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, epochs=10,verbose=1,validation_data=(X_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 283us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0027551094055176, 0.6617]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test, verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_save = keras.callbacks.ModelCheckpoint(filepath=\"file.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only= False, mode='auto', period=1)\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\n",
    "#learning_rate = keras.callbacks.LearningRateScheduler(schedule, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping Callback hinzuf√ºgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 34s 679us/step - loss: 0.5275 - acc: 0.8179 - val_loss: 1.0298 - val_acc: 0.6702\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 34s 672us/step - loss: 0.4890 - acc: 0.8402 - val_loss: 1.0635 - val_acc: 0.6847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbc207f3208>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, callbacks=[file_save, early_stopping] ,batch_size=512, epochs=10,verbose=1,validation_data=(X_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-50bd5643f350>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     horizontal_flip=True)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# fits the model on batches with real-time data augmentation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
